{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a Master Dataset\n",
    "\n",
    "This notebook merges preprocessed datasets from the \"pre_processed_datasets\" folder into a single master dataset, which is saved in the \"master_dataset\" folder.\n",
    "The merging steps include:\n",
    " - Loading the preprocessed datasets.\n",
    " - Merging them on the common column `Day Index`.\n",
    " - Saving the final merged dataset to the \"master_dataset\" folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the Pandas Library\n",
    "\n",
    "I imported the **Pandas** library, which is essential for data manipulation and analysis. Pandas provides powerful tools for handling datasets, including reading, merging, and exporting data, making it a crucial part of this project.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  # Import the pandas library for data manipulation and analysis\n",
    "import os # Import os for working with file paths/location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining Pre Processed Dataset Paths\n",
    "I used relative paths for specifying the locations of the cleaned datasets. This ensures that the notebook works on any machine as long as the dataset files are placed in the expected directory structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Google Clicks Path Exists: True\n",
      "Facebook Impressions Path Exists: True\n",
      "Quantity Path Exists: True\n",
      "Current Working Directory: c:\\Users\\nitin\\OneDrive\\Documents\\Infosys Springboard Internship Files\\NitinMishra-Infosys-Nov24\\python files\n"
     ]
    }
   ],
   "source": [
    "google_clicks_path = '../datasets/pre_processed_datasets/pre_processed_ProductA_google_clicks.xlsx'\n",
    "fb_impressions_path = '../datasets/pre_processed_datasets/pre_processed_ProductA_fb_impressions.xlsx'\n",
    "quantity_path = '../datasets/pre_processed_datasets/pre_processed_ProductA.xlsx'\n",
    "\n",
    "# Verify each file\n",
    "print(f\"Google Clicks Path Exists: {os.path.exists(google_clicks_path)}\")\n",
    "print(f\"Facebook Impressions Path Exists: {os.path.exists(fb_impressions_path)}\")\n",
    "print(f\"Quantity Path Exists: {os.path.exists(quantity_path)}\")\n",
    "\n",
    "# Print the current working directory for confirmation\n",
    "print(f\"Current Working Directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Individual Datasets\n",
    "\n",
    "To begin the data consolidation process, I loaded three separate datasets into individual DataFrames:\n",
    "\n",
    "1. **Google Clicks**:\n",
    "   - File Path: `../datasets/pre_processed_datasets/pre_processed_ProductA.xlsx`\n",
    "   - Contains preprocessed data on clicks generated through Google.\n",
    "\n",
    "2. **Facebook Impressions**:\n",
    "   - File Path: `./datasets/pre_processed_datasets/pre_processed_ProductA_fb_impressions.xlsx`\n",
    "   - Includes preprocessed impression data from Facebook.\n",
    "\n",
    "3. **Quantity Data**:\n",
    "   - File Path: `./datasets/pre_processed_datasets/pre_processed_ProductA.xlsx`\n",
    "   - Provides preprocessed sales-related data for Product A.\n",
    "\n",
    "Each dataset was read into a Pandas DataFrame using the `read_excel` function (since the preprocessed datasets were of `.xlsx` type) , ensuring the data is ready for merging and further processing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets Loaded successfully !\n"
     ]
    }
   ],
   "source": [
    "# Load each Excel file into a DataFrame\n",
    "google_clicks = pd.read_excel(google_clicks_path)\n",
    "fb_impressions = pd.read_excel(fb_impressions_path)\n",
    "quantity = pd.read_excel(quantity_path)\n",
    "\n",
    "print(\"Datasets Loaded successfully !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merging Datasets\n",
    "\n",
    "To create a unified master dataset, I merged the three individual DataFrames on their common column, **`Day Index`**. Here's what this step accomplished:\n",
    "\n",
    "- Combined data from:\n",
    "  - **Google Clicks**\n",
    "  - **Facebook Impressions**\n",
    "  - **Quantity Data**\n",
    "- Used Pandas' `merge` method to join the datasets, ensuring alignment based on the **`Day Index`** column.\n",
    "\n",
    "This operation resulted in a comprehensive dataset that consolidates all relevant metrics, making it ready for analysis and visualization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets merged successfully\n"
     ]
    }
   ],
   "source": [
    "# Merge the three DataFrames on the common column \"Day Index\"\n",
    "# This combines all data into a single master dataset\n",
    "master_dataset = google_clicks.merge(fb_impressions, on=\"Day Index\").merge(quantity, on=\"Day Index\")\n",
    "\n",
    "print(\"Datasets merged successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the Master Dataset\n",
    "\n",
    "After merging the datasets, I saved the resulting master dataset to an Excel file for future use. Here's what I did:\n",
    "\n",
    "- Used the `to_excel` method to export the merged DataFrame to an Excel file.\n",
    "- Saved the file at the following location:\n",
    "  `./datasets/master_dataset/master_dataset.xlsx`\n",
    "- Ensured that the **index was excluded** (`index=False`) for a cleaner output.\n",
    "\n",
    "This step makes the unified dataset accessible for subsequent analyses and visualizations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged data saved successfully at ../datasets/master_dataset/master_dataset.xlsx\n"
     ]
    }
   ],
   "source": [
    "save_path = '../datasets/master_dataset/master_dataset.xlsx'\n",
    "os.makedirs(os.path.dirname(save_path),exist_ok = True) # Ensure that directory exists\n",
    "master_dataset.to_excel(save_path, index = False)\n",
    "\n",
    "print(f\"Merged data saved successfully at {save_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
